package tui

import (
	"context"
	"fmt"
	"syscall"

	"github.com/AvengeMedia/dgop/gops"
	"github.com/AvengeMedia/dgop/models"
	tea "github.com/charmbracelet/bubbletea"
)

type fetchDataMsg struct {
	metrics    *models.SystemMetrics
	err        error
	generation int
	cpuCursor  string
}

type fetchProcessesMsg struct {
	processes  []*models.ProcessInfo
	err        error
	generation int
	procCursor string
}

type fetchNetworkMsg struct {
	rates *models.NetworkRateResponse
	err   error
}

type fetchDiskMsg struct {
	rates *models.DiskRateResponse
	err   error
}

type fetchTempMsg struct {
	temps []models.TemperatureSensor
	err   error
}

type processKillResultMsg struct {
	message string
}

func killProcess(pid int32, force bool) tea.Cmd {
	return func() tea.Msg {
		sig := syscall.SIGTERM
		sigName := "SIGTERM"
		if force {
			sig = syscall.SIGKILL
			sigName = "SIGKILL"
		}
		err := syscall.Kill(int(pid), sig)
		if err != nil {
			return processKillResultMsg{message: fmt.Sprintf("Failed to kill PID %d: %v", pid, err)}
		}
		return processKillResultMsg{message: fmt.Sprintf("Sent %s to PID %d", sigName, pid)}
	}
}

func (m *ResponsiveTUIModel) fetchData() tea.Cmd {
	generation := m.fetchGeneration
	cpuCursor := m.cpuCursor
	sortBy := m.sortBy
	procLimit := m.procLimit
	return func() tea.Msg {
		params := gops.MetaParams{
			SortBy:    sortBy,
			ProcLimit: procLimit,
			EnableCPU: true,
			CPUCursor: cpuCursor,
		}

		modules := []string{"cpu", "memory", "system"}
		metrics, err := m.gops.GetMeta(context.Background(), modules, params)

		if err != nil {
			return fetchDataMsg{err: err, generation: generation}
		}

		systemMetrics := &models.SystemMetrics{
			CPU:        metrics.CPU,
			Memory:     metrics.Memory,
			System:     metrics.System,
			Network:    metrics.Network,
			Disk:       metrics.Disk,
			DiskMounts: nil,
			Processes:  metrics.Processes,
		}

		newCPUCursor := ""
		if metrics.CPU != nil {
			newCPUCursor = metrics.CPU.Cursor
		}

		return fetchDataMsg{
			metrics:    systemMetrics,
			err:        nil,
			generation: generation,
			cpuCursor:  newCPUCursor,
		}
	}
}

func (m *ResponsiveTUIModel) fetchProcessData() tea.Cmd {
	generation := m.fetchGeneration
	procCursor := m.procCursor
	sortBy := m.sortBy
	procLimit := m.procLimit
	mergeChildren := m.mergeChildren

	return func() tea.Msg {
		result, err := m.gops.GetProcessesWithCursor(sortBy, procLimit, true, procCursor, mergeChildren)
		if err != nil {
			return fetchProcessesMsg{err: err, generation: generation}
		}

		return fetchProcessesMsg{
			processes:  result.Processes,
			err:        nil,
			generation: generation,
			procCursor: result.Cursor,
		}
	}
}

func (m *ResponsiveTUIModel) fetchNetworkData() tea.Cmd {
	return func() tea.Msg {
		rates, err := m.gops.GetNetworkRates(m.networkCursor)
		return fetchNetworkMsg{rates: rates, err: err}
	}
}

func (m *ResponsiveTUIModel) fetchDiskData() tea.Cmd {
	return func() tea.Msg {
		rates, err := m.gops.GetDiskRates(m.diskCursor)
		return fetchDiskMsg{rates: rates, err: err}
	}
}

func (m *ResponsiveTUIModel) fetchTemperatureData() tea.Cmd {
	return func() tea.Msg {
		temps, err := m.gops.GetSystemTemperatures()
		return fetchTempMsg{temps: temps, err: err}
	}
}
